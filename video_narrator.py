# coding: utf-8
import logging
import os
import base64
import shutil
import time
import errno
from openai import OpenAI


class ImageAnalyzer:
    def __init__(self, openai_api_key, voice_id, base_url=None, logger=None):
        self.latest_audio_path = None
        self.logger = logger if logger is not None else logging.getLogger(__name__)
        if base_url:
            self.client = OpenAI(api_key=openai_api_key, base_url=base_url)
        else:
            self.client = OpenAI(api_key=openai_api_key)


    def encode_image(self, image_path):
        while True:
            try:
                with open(image_path, "rb") as image_file:
                    return base64.b64encode(image_file.read()).decode("utf-8")
            except IOError as e:
                if e.errno != errno.EACCES:
                    raise
                time.sleep(0.1)

    def generate_new_line(self, base64_image):
        data = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "Describe this image"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}"
                    }
                },
            ],
        },
        ]
        self.logger.info("ğŸ¤– AI is analyzing the image...")
        # self.logger.info(data)
        return data

    def analyze_image(self, base64_image, script):
        try:
            # self.logger.info(f"æ­£åœ¨å‘é€çš„å›¾åƒæ•°æ®: {self.generate_new_line(base64_image)}")
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                             {
                                 "role": "system",
                                 "content": """
                        You are Sir David Attenborough. Narrate the picture of the human as if it is a nature documentary.
                        Make it snarky and funny. Don't repeat yourself. Make it short. If I do anything remotely interesting, make a big deal about it!
                        """,
                             },
                         ]
                         + script
                         + self.generate_new_line(base64_image),
                max_tokens=1200,
            )
            # ç¡®ä¿å“åº”ä¸­åŒ…å«é¢„æœŸçš„æ•°æ®
            if response.choices and len(response.choices) > 0 and response.choices[0].message:
                return response.choices[0].message.content
            else:
                self.logger.error("å“åº”ç¼ºå°‘é¢„æœŸçš„æ•°æ®ã€‚")
                self.logger.info(f"å“åº”å†…å®¹: {response}")
        except Exception as e:
            self.logger.error(f"åˆ†æå›¾åƒæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            self.logger.debug(f"é”™è¯¯è¯¦æƒ…:{response}")


    def _openai_play_audio_with_chunking(self, text, voice="alloy"):
        self.logger.info("ğŸ”Š Playing audio...")
        narration_dir = os.path.join(os.getcwd(), "narration")
        if not os.path.exists(narration_dir):
            os.makedirs(narration_dir)
            
        # å°†æ–‡æœ¬åˆ†æˆå¤šä¸ªå°å—ï¼Œæ¯ä¸ªä¸è¶…è¿‡ 4096 ä¸ªå­—ç¬¦
        chunks = [text[i:i+4096] for i in range(0, len(text), 4096)]
        
        # ç”¨äºå­˜å‚¨ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        self.latest_audio_path = []
        
        # æ£€æŸ¥ voice å‚æ•°æ˜¯å¦æœ‰æ•ˆ
        valid_voices = ['nova', 'shimmer', 'echo', 'onyx', 'fable', 'alloy']
        if voice not in valid_voices:
            self.logger.error(f"æ— æ•ˆçš„è¯­éŸ³é€‰æ‹©: {voice}. å°†ä½¿ç”¨é»˜è®¤å€¼ 'alloy'.")
            voice = 'alloy'
        
        for chunk in chunks:
            self.logger.info(f"æ­£åœ¨ç”Ÿæˆç¬¬ {len(self.latest_audio_path) + 1} ä¸ªéŸ³é¢‘æ–‡ä»¶ç‰‡æ®µ...")
            try:
                response = self.client.audio.speech.create(
                    model="tts-1",
                    voice=voice,
                    input=chunk,
                )
            except Exception as e:
                self.logger.error(f"ç”ŸæˆéŸ³é¢‘æ–‡ä»¶ç‰‡æ®µæ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue
            
            # ç”Ÿæˆæ–°çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            speech_file_index = len(self.latest_audio_path) + 1
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            speech_file_path = os.path.join(narration_dir, f"speech_{speech_file_index}_{timestamp}.mp3")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»å­˜åœ¨
            if not os.path.exists(speech_file_path):
                self.logger.info(f"æ­£åœ¨ä¿å­˜ç¬¬ {speech_file_index} ä¸ªéŸ³é¢‘æ–‡ä»¶ç‰‡æ®µåˆ° {speech_file_path}...")
                try:
                    with open(speech_file_path, "wb") as f:
                        f.write(response.content)
                except Exception as e:
                    self.logger.error(f"ä¿å­˜éŸ³é¢‘æ–‡ä»¶ç‰‡æ®µ {speech_file_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    continue
                self.latest_audio_path.append(speech_file_path)
                self.logger.info("ğŸµ Audio saved to: %s", speech_file_path)
            else:
                self.logger.info(f"æ–‡ä»¶ {speech_file_path} å·²å­˜åœ¨, è·³è¿‡ç”Ÿæˆ.")
                self.latest_audio_path.append(speech_file_path)
            
        self.logger.info("ğŸ¯ All audio files generated.")
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œå°±ç›´æ¥è¿”å›è¯¥æ–‡ä»¶è·¯å¾„
        if len(self.latest_audio_path) == 1:
            self.logger.info(f"ğŸ‰ Final audio file saved to: {self.latest_audio_path[0]}")
            return self.latest_audio_path[0]
        
        # åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
        final_audio_path = os.path.join(narration_dir, f"final_narration_{timestamp}.mp3")
        self.logger.info(f"æ­£åœ¨åˆå¹¶ {len(self.latest_audio_path)} ä¸ªéŸ³é¢‘æ–‡ä»¶åˆ° {final_audio_path}...")
        self._merge_audio_files(self.latest_audio_path, final_audio_path)
        
        self.logger.info(f"ğŸ‰ Final audio file saved to: {final_audio_path}")
        return final_audio_path









    def _merge_audio_files(self, input_files, output_file):
        """å°†å¤šä¸ªéŸ³é¢‘æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªæ–‡ä»¶"""
        import subprocess

        # åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶è·¯å¾„çš„æ–‡æœ¬æ–‡ä»¶
        concat_file = os.path.join("narration", "concat.txt")
        try:
            with open(concat_file, "w") as f:
                for file_path in input_files:
                    f.write(f"file '{file_path}'\n")
        except Exception as e:
            self.logger.error(f"åˆ›å»º concat.txt æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return

        # ä½¿ç”¨ ffmpeg å‘½ä»¤åˆå¹¶éŸ³é¢‘æ–‡ä»¶
        try:
            subprocess.run(["ffmpeg", "-f", "concat", "-safe", "0", "-i", concat_file, "-c", "copy", output_file], check=True)
        except subprocess.CalledProcessError as e:
            self.logger.error(f"åˆå¹¶éŸ³é¢‘æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        self._delete_files([concat_file] + input_files, max_retries=3, retry_delay=0.5)


    def _delete_files(self, file_paths, max_retries=3, retry_delay=0.5):
        """å°è¯•åˆ é™¤æ–‡ä»¶,å¦‚æœå¤±è´¥åˆ™é‡è¯•"""
        for file_path in file_paths:
            num_retries = 0
            while num_retries < max_retries:
                try:
                    os.remove(file_path)
                    break
                except OSError as e:
                    self.logger.error(f"åˆ é™¤æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    num_retries += 1
                    if num_retries < max_retries:
                        self.logger.info(f"æ­£åœ¨é‡è¯•åˆ é™¤æ–‡ä»¶ {file_path}...")
                        time.sleep(retry_delay)
                    else:
                        self.logger.info(f"å·²æˆåŠŸåˆ é™¤æ–‡ä»¶ {file_path}")




    def get_latest_audio_path(self):
        return self.latest_audio_path

    def main(self,voice="alloy"):
        script = []
        time.sleep(3)
        frames_dir = os.path.join(os.getcwd(), "video_frames")
        frame_files = [f for f in sorted(os.listdir(frames_dir)) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

        self.logger.info(f"æ‰¾åˆ° {len(frame_files)} ä¸ªå›¾åƒæ–‡ä»¶è¿›è¡Œåˆ†æã€‚")

        ai_message = ''
        for index, frame_file in enumerate(frame_files):
            frame_path = os.path.join(frames_dir, frame_file)
            base64_image = self.encode_image(frame_path)
            # ä¸ºäº†æé«˜æ—¥å¿—çš„å¯è¯»æ€§ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ—¥å¿—ä¸­æ·»åŠ æ–‡ä»¶ç´¢å¼•å’Œåç§°
            self.logger.info(f"ğŸ‘€ æ­£åœ¨åˆ†æç¬¬ {index + 1}/{len(frame_files)} ä¸ªæ–‡ä»¶: {frame_file}...")
            analysis = self.analyze_image(base64_image, script=script)

            if analysis:  # ç¡®ä¿åˆ†æç»“æœä¸ä¸ºç©º
                self.logger.info("ğŸ™ï¸ åˆ†æç»“æœ:")
                self.logger.info(analysis)
                script.append({"role": "assistant", "content": analysis})
                ai_message += analysis + " "  # æ·»åŠ ç©ºæ ¼ä»¥åˆ†éš”ä¸åŒå¸§çš„åˆ†æç»“æœ
                time.sleep(5)  # æ ¹æ®éœ€è¦è°ƒæ•´ç­‰å¾…æ—¶é—´
            else:
                self.logger.info("æ²¡æœ‰è·å–åˆ°åˆ†æç»“æœã€‚")

        # æ£€æŸ¥ai_messageæ˜¯å¦ä¸ºç©ºï¼Œé¿å…å°è¯•æ’­æ”¾ç©ºæ¶ˆæ¯
        if ai_message:
            self._openai_play_audio_with_chunking(text=ai_message,voice=voice)
        else:
            self.logger.info("æ²¡æœ‰ç”Ÿæˆä»»ä½•éŸ³é¢‘æ¶ˆæ¯ã€‚")
