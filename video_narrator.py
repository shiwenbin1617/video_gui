# coding: utf-8
import logging
import os
import base64
import shutil
import time
import errno
from openai import OpenAI


class ImageAnalyzer:
    def __init__(self, openai_api_key, voice_id, base_url=None, logger=None):
        self.latest_audio_path = None
        self.logger = logger if logger is not None else logging.getLogger(__name__)
        if base_url:
            self.client = OpenAI(api_key=openai_api_key, base_url=base_url)
        else:
            self.client = OpenAI(api_key=openai_api_key)

    def encode_image(self, image_path):
        while True:
            try:
                with open(image_path, "rb") as image_file:
                    return base64.b64encode(image_file.read()).decode("utf-8")
            except IOError as e:
                if e.errno != errno.EACCES:
                    raise
                time.sleep(0.1)

    def generate_new_line(self, base64_image):
        return [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "Describe this image"},
                    {
                        "type": "image_url",
                        "image_url": f"data:image/jpeg;base64,{base64_image}",
                    },
                ],
            },
        ]

    def analyze_image(self, base64_image, script):
        try:
            self.logger.info(f"æ­£åœ¨å‘é€çš„å›¾åƒæ•°æ®: {self.generate_new_line(base64_image)}")
            response = self.client.chat.completions.create(
                model="gpt-4-vision-preview",
                messages=[
                             {
                                 "role": "system",
                                 "content": """
                        You are Sir David Attenborough. Narrate the picture of the human as if it is a nature documentary.
                        Make it snarky and funny. Don't repeat yourself. Make it short. If I do anything remotely interesting, make a big deal about it!
                        """,
                             },
                         ]
                         + script
                         + self.generate_new_line(base64_image),
                max_tokens=1200,
            )
            # ç¡®ä¿å“åº”ä¸­åŒ…å«é¢„æœŸçš„æ•°æ®
            if response.choices and len(response.choices) > 0 and response.choices[0].message:
                return response.choices[0].message.content
            else:
                self.logger.error("å“åº”ç¼ºå°‘é¢„æœŸçš„æ•°æ®ã€‚")
                self.logger.info(f"å“åº”å†…å®¹: {response}")
        except Exception as e:
            self.logger.error(f"åˆ†æå›¾åƒæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            self.logger.debug(f"é”™è¯¯è¯¦æƒ…:{response}")

    def _openai_play_audio(self, text, voice="alloy"):
        self.logger.info("ğŸ”Š Playing audio...")
        response = self.client.audio.speech.create(
            model="tts-1",
            voice=voice,
            input=text
        )
        speech_file_path = os.path.join("narration", "speech.mp3")
        response.stream_to_file(speech_file_path)
        self.latest_audio_path = speech_file_path
        self.logger.info("ğŸµ Audio saved to: %s", speech_file_path)

    def get_latest_audio_path(self):
        return self.latest_audio_path

    def main(self,voice="alloy"):
        script = []
        time.sleep(3)
        frames_dir = os.path.join(os.getcwd(), "video_frames")
        frame_files = [f for f in sorted(os.listdir(frames_dir)) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

        self.logger.info(f"æ‰¾åˆ° {len(frame_files)} ä¸ªå›¾åƒæ–‡ä»¶è¿›è¡Œåˆ†æã€‚")

        ai_message = ''
        for index, frame_file in enumerate(frame_files):
            frame_path = os.path.join(frames_dir, frame_file)
            base64_image = self.encode_image(frame_path)

            # ä¸ºäº†æé«˜æ—¥å¿—çš„å¯è¯»æ€§ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ—¥å¿—ä¸­æ·»åŠ æ–‡ä»¶ç´¢å¼•å’Œåç§°
            self.logger.info(f"ğŸ‘€ æ­£åœ¨åˆ†æç¬¬ {index + 1}/{len(frame_files)} ä¸ªæ–‡ä»¶: {frame_file}...")
            analysis = self.analyze_image(base64_image, script=script)

            if analysis:  # ç¡®ä¿åˆ†æç»“æœä¸ä¸ºç©º
                self.logger.info("ğŸ™ï¸ åˆ†æç»“æœ:")
                self.logger.info(analysis)
                script.append({"role": "assistant", "content": analysis})
                ai_message += analysis + " "  # æ·»åŠ ç©ºæ ¼ä»¥åˆ†éš”ä¸åŒå¸§çš„åˆ†æç»“æœ
                time.sleep(5)  # æ ¹æ®éœ€è¦è°ƒæ•´ç­‰å¾…æ—¶é—´
            else:
                self.logger.info("æ²¡æœ‰è·å–åˆ°åˆ†æç»“æœã€‚")

        # æ£€æŸ¥ai_messageæ˜¯å¦ä¸ºç©ºï¼Œé¿å…å°è¯•æ’­æ”¾ç©ºæ¶ˆæ¯
        if ai_message:
            self._openai_play_audio(text=ai_message,voice=voice)
        else:
            self.logger.info("æ²¡æœ‰ç”Ÿæˆä»»ä½•éŸ³é¢‘æ¶ˆæ¯ã€‚")
